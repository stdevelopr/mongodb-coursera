{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "import pprint\n",
    "\n",
    "client = MongoClient(\"mongodb://stdevelopr:devpass@cluster0-shard-00-00-eff6m.mongodb.net:27017,cluster0-shard-00-01-eff6m.mongodb.net:27017,cluster0-shard-00-02-eff6m.mongodb.net:27017/test?ssl=true&replicaSet=Cluster0-shard-0&authSource=admin&retryWrites=true&w=majority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'top language combinations': [{'_id': 'English', 'count': 25325},\n",
      "                                {'_id': 'French', 'count': 1784},\n",
      "                                {'_id': 'Italian', 'count': 1480},\n",
      "                                {'_id': 'Japanese', 'count': 1290},\n",
      "                                {'_id': '', 'count': 1114},\n",
      "                                {'_id': 'Spanish', 'count': 875},\n",
      "                                {'_id': 'Russian', 'count': 777},\n",
      "                                {'_id': 'English, Spanish', 'count': 728},\n",
      "                                {'_id': 'German', 'count': 674},\n",
      "                                {'_id': 'English, French', 'count': 584}],\n",
      "  'unusual combinations shared by': [{'_id': {'max': 2, 'min': 1},\n",
      "                                      'language combinations': 1868},\n",
      "                                     {'_id': {'max': 498, 'min': 2},\n",
      "                                      'language combinations': 733}]}]\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        '$sortByCount': \"$language\"\n",
    "    },\n",
    "    {\n",
    "        '$facet': {\n",
    "            'top language combinations' : [{'$limit': 10}],\n",
    "            'unusual combinations shared by': [{'$skip': 10}, {\n",
    "                '$bucketAuto': {\n",
    "                    'groupBy': '$count',\n",
    "                    'buckets': 2,\n",
    "                    'output': {\n",
    "                        'language combinations': {'$sum': 1}\n",
    "                    }\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "pprint.pprint(list(client.analytics.movies_initial.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing two types of analysis simultaneously presents to the aggregation framework the problem that with the pipeline it can really only process, the documents to one outcome.\\\n",
    "This type of situation frequently arises, so the aggregation framework actually does support running multiple pipelines in parallel, with the use of the dollar facet stage.\\\n",
    "Let's use a dollar facet stage to provide both types of summary information.\\\n",
    "Details on specific language combinations and just some raw counts on unusual accommodations.\\\n",
    "\\\\$facet enables you to define multiple pipelines through which to process the same input documents.\\\n",
    "Defining two fields, each has as its value, an array.\\\n",
    "Each one of these arrays defines a separate pipeline that will be processed in parallel.\\\n",
    "And the result of running each pipeline will be stored as the value of these keys in the output from this \\\\$facet stage.\\\n",
    "In this case both pipelines will receive as input the stream of documents admitted by the sort by count stage in the main pipeline.\\\n",
    "This pipeline will simply take the input it receives from the sort by count stage and limit it to the first 100 documents.\\\n",
    "The second pipeline uses two stages, skip and buckatAuto.\\\n",
    "Once a number of documents equal to the skip value has passed through a skip stage, it will pass any additional documents on as output.\\\n",
    "The output servers as imput to \\$bucketAuto, wich is similar to the group stage except, it automatically defines a list of buckets into which it will group input documents. Rather than create groups based on the single value, bucket auto will automatically define ranges of values, and group all documents that fall within that range into the bucket.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
